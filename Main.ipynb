{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingRegressor\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import os\n",
    "import Levenshtein\n",
    "from gensim.utils import tokenize\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "from gensim.similarities import MatrixSimilarity\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from scipy import spatial\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: read data\n",
    "\n",
    "# Step 1.1: read the stemmed data\n",
    "df_train = pd.read_csv('stemmed_data/train.csv', encoding = \"ISO-8859-1\")\n",
    "df_test = pd.read_csv('stemmed_data/test.csv', encoding = \"ISO-8859-1\")\n",
    "df_desc = pd.read_csv('stemmed_data/product_descriptions.csv', encoding = \"ISO-8859-1\")\n",
    "df_desc = df_desc[['product_uid', 'product_description']]\n",
    "\n",
    "df_attr_material = pd.read_csv('stemmed_data/attr_material.csv', encoding = \"ISO-8859-1\").dropna(how='any')\n",
    "df_attr_brand = pd.read_csv('stemmed_data/attr_brand.csv', encoding = \"ISO-8859-1\").dropna(how='any')\n",
    "df_attr_bullets = pd.read_csv('stemmed_data/attr_bullets.csv', encoding = \"ISO-8859-1\").dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add bullets to description\n",
    "df_desc = pd.merge(df_desc, df_attr_bullets, how='left', on='product_uid')\n",
    "df_desc['product_description'] = df_desc['product_description'].map(lambda x: x + ' ') + df_desc['bullets']\n",
    "df_desc = df_desc.drop(['bullets'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   product_uid                                product_description  \\\n",
      "0       100001  not onli do angl make joint stronger, they als...   \n",
      "\n",
      "               brand      material  \n",
      "0  simpson strong-ti  galvan steel  \n"
     ]
    }
   ],
   "source": [
    "# # add brand and material\n",
    "df_desc = pd.merge(df_desc, df_attr_brand, how='left', on='product_uid')\n",
    "df_desc = pd.merge(df_desc, df_attr_material, how='left', on='product_uid')\n",
    "print(df_desc.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [id, product_uid, product_title, search_term, product_description, brand, material]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.merge(df_train, df_desc, how='left', on='product_uid')\n",
    "df_train['material'] = df_train['material'].fillna(' ')\n",
    "print(df_train.head(0))\n",
    "df_test = pd.merge(df_test, df_desc, how='left', on='product_uid')\n",
    "df_test['material'] = df_test['material'].fillna(' ')\n",
    "print(df_test.head(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('midterm_data/df_train.csv', index=False)\n",
    "df_test.to_csv('midterm_data/df_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('midterm_data/df_train.csv')\n",
    "df_train['product_description'] = df_train.apply(lambda x: x['product_description'], axis=1)\n",
    "df_train['brand'] = df_train.apply(lambda x: x['brand'], axis=1)\n",
    "df_train['material'] = df_train.apply(lambda x: x['material'], axis=1)\n",
    "df_test = pd.read_csv('midterm_data/df_test.csv')\n",
    "df_test['product_description'] = df_test.apply(lambda x: x['product_description'], axis=1)\n",
    "df_test['brand'] = df_test.apply(lambda x: x['brand'], axis=1)\n",
    "df_test['material'] = df_test.apply(lambda x: x['material'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  product_uid                   product_title   search_term  relevance  \\\n",
      "0   2       100001  simpson strong-ti 12-gaug angl  angl bracket        3.0   \n",
      "\n",
      "                                 product_description              brand  \\\n",
      "0  not onli do angl make joint stronger, they als...  simpson strong-ti   \n",
      "\n",
      "       material  dist_in_title  dist_in_desc           ...             \\\n",
      "0  galvan steel       0.190476      0.021602           ...              \n",
      "\n",
      "   common_brand  common_material  tfidf_cos_sim_in_title  \\\n",
      "0             0                0                0.274629   \n",
      "\n",
      "   tfidf_cos_sim_in_desc  tfidf_cos_sim_in_brand  tfidf_cos_sim_in_material  \\\n",
      "0               0.175537                     0.0                        0.0   \n",
      "\n",
      "   w2v_cos_sim_in_title  w2v_cos_sim_in_desc  w2v_cos_sim_in_brand  \\\n",
      "0              0.483795             0.430817              0.150791   \n",
      "\n",
      "   w2v_cos_sim_in_material  \n",
      "0                 0.215702  \n",
      "\n",
      "[1 rows x 24 columns]\n",
      "   id  product_uid                   product_title       search_term  \\\n",
      "0   1       100001  simpson strong-ti 12-gaug angl  90 degre bracket   \n",
      "\n",
      "                                 product_description              brand  \\\n",
      "0  not onli do angl make joint stronger, they als...  simpson strong-ti   \n",
      "\n",
      "       material  dist_in_title  dist_in_desc  dist_in_brand  \\\n",
      "0  galvan steel       0.173913      0.025112       0.181818   \n",
      "\n",
      "            ...             common_brand  common_material  \\\n",
      "0           ...                        0                0   \n",
      "\n",
      "   tfidf_cos_sim_in_title  tfidf_cos_sim_in_desc  tfidf_cos_sim_in_brand  \\\n",
      "0                     0.0                    0.0                     0.0   \n",
      "\n",
      "   tfidf_cos_sim_in_material  w2v_cos_sim_in_title  w2v_cos_sim_in_desc  \\\n",
      "0                        0.0              0.313699              0.17586   \n",
      "\n",
      "   w2v_cos_sim_in_brand  w2v_cos_sim_in_material  \n",
      "0              0.082488                 0.212213  \n",
      "\n",
      "[1 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_train.head(1))\n",
    "print(df_test.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_common_word(str1, str2):\n",
    "    '''\n",
    "    Count common words in two strings\n",
    "    :param str1: string\n",
    "    :param str2: string\n",
    "    :return: number of common words\n",
    "    '''\n",
    "    return sum([int(str2.find(word) >= 0) for word in str1.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use common words number in search term\n",
    "# train\n",
    "df_train['common_title'] = \\\n",
    "    df_train.apply(lambda x: str_common_word(x['product_title'], x['search_term']), axis=1)\n",
    "df_train['common_desc'] = \\\n",
    "    df_train.apply(lambda x: str_common_word(x['product_description'], x['search_term']), axis=1)\n",
    "df_train['common_brand'] = \\\n",
    "    df_train.apply(lambda x: str_common_word(x['brand'], x['search_term']), axis=1)\n",
    "df_train['common_material'] = \\\n",
    "    df_train.apply(lambda x: str_common_word(x['material'], x['search_term']), axis=1)\n",
    "\n",
    "# test\n",
    "df_test['common_title'] = \\\n",
    "    df_test.apply(lambda x: str_common_word(x['product_title'], x['search_term']), axis=1)\n",
    "df_test['common_desc'] = \\\n",
    "    df_test.apply(lambda x: str_common_word(x['product_description'], x['search_term']), axis=1)\n",
    "df_test['common_brand'] = \\\n",
    "    df_test.apply(lambda x: str_common_word(x['brand'], x['search_term']), axis=1)\n",
    "df_test['common_material'] = \\\n",
    "    df_test.apply(lambda x: str_common_word(x['material'], x['search_term']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use levenshtein distance\n",
    "# train\n",
    "df_train['dist_in_title'] = df_train.apply(lambda x: Levenshtein.ratio(x['search_term'],x['product_title']), axis=1)\n",
    "df_train['dist_in_desc'] = df_train.apply(lambda x: Levenshtein.ratio(x['search_term'],x['product_description']), axis=1)\n",
    "df_train['dist_in_brand'] = df_train.apply(lambda x: Levenshtein.ratio(x['search_term'],x['brand']), axis=1)\n",
    "df_train['dist_in_material'] = df_train.apply(lambda x: Levenshtein.ratio(x['search_term'],x['material']), axis=1)\n",
    "\n",
    "# test\n",
    "df_test['dist_in_title'] = df_test.apply(lambda x: Levenshtein.ratio(x['search_term'],x['product_title']), axis=1)\n",
    "df_test['dist_in_desc'] = df_test.apply(lambda x: Levenshtein.ratio(x['search_term'],x['product_description']), axis=1)\n",
    "df_test['dist_in_brand'] = df_test.apply(lambda x: Levenshtein.ratio(x['search_term'],x['brand']), axis=1)\n",
    "df_test['dist_in_material'] = df_test.apply(lambda x: Levenshtein.ratio(x['search_term'],x['material']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  product_uid                   product_title   search_term  relevance  \\\n",
      "0   2       100001  simpson strong-ti 12-gaug angl  angl bracket        3.0   \n",
      "\n",
      "                                 product_description              brand  \\\n",
      "0  not onli do angl make joint stronger, they als...  simpson strong-ti   \n",
      "\n",
      "       material  dist_in_title  dist_in_desc  dist_in_brand  dist_in_material  \\\n",
      "0  galvan steel       0.190476      0.021602       0.275862          0.333333   \n",
      "\n",
      "   common_title  common_desc  common_brand  common_material  \n",
      "0             1            7             0                0  \n",
      "   id  product_uid                   product_title       search_term  \\\n",
      "0   1       100001  simpson strong-ti 12-gaug angl  90 degre bracket   \n",
      "\n",
      "                                 product_description              brand  \\\n",
      "0  not onli do angl make joint stronger, they als...  simpson strong-ti   \n",
      "\n",
      "       material  dist_in_title  dist_in_desc  dist_in_brand  dist_in_material  \\\n",
      "0  galvan steel       0.173913      0.025112       0.181818          0.214286   \n",
      "\n",
      "   common_title  common_desc  common_brand  common_material  \n",
      "0             0            4             0                0  \n"
     ]
    }
   ],
   "source": [
    "print(df_train.head(1))\n",
    "print(df_test.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(['id', 'product_uid', 'product_title', 'search_term', 'relevance', 'product_description'\\\n",
    "                      , 'brand', 'material'\\\n",
    "#                       , 'common_title', 'common_desc', 'common_brand', 'common_material'\\\n",
    "                         # keeping these attributes\n",
    "#                       , 'dist_in_title', 'dist_in_desc', 'dist_in_brand', 'dist_in_material'\\\n",
    "#                       , 'tfidf_cos_sim_in_title' , 'tfidf_cos_sim_in_desc', 'tfidf_cos_sim_in_brand' , 'tfidf_cos_sim_in_material' \\\n",
    "#                         , 'w2v_cos_sim_in_title'\\\n",
    "#                          , 'w2v_cos_sim_in_desc'\\\n",
    "#                          , 'w2v_cos_sim_in_brand'\\\n",
    "                         , 'w2v_cos_sim_in_material'\\\n",
    "                        ], axis=1).values\n",
    "y_train = df_train['relevance'].values\n",
    "X_test = df_test.drop(['id', 'product_uid', 'product_title', 'search_term', 'product_description'\\\n",
    "                      , 'brand', 'material'\\\n",
    "#                       , 'common_title', 'common_desc', 'common_brand', 'common_material'\\\n",
    "                       # keeping these attributes\n",
    "#                       , 'dist_in_title', 'dist_in_desc', 'dist_in_brand', 'dist_in_material'\\\n",
    "#                       , 'tfidf_cos_sim_in_title' , 'tfidf_cos_sim_in_desc', 'tfidf_cos_sim_in_brand' , 'tfidf_cos_sim_in_material' \\\n",
    "#                       , 'w2v_cos_sim_in_title'\\\n",
    "#                        , 'w2v_cos_sim_in_desc'\\\n",
    "#                        , 'w2v_cos_sim_in_brand'\\\n",
    "                       , 'w2v_cos_sim_in_material'\\\n",
    "                      ], axis=1).values\n",
    "test_ids = df_test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error for param 1 is: [0.51482473 0.50731861 0.5033553  0.50902013 0.53395302]\n",
      "error for param 3 is: [0.5051083  0.49403116 0.49000244 0.49816786 0.5259801 ]\n",
      "error for param 5 is: [0.49889898 0.4876352  0.48354359 0.49171781 0.51801123]\n",
      "error for param 6 is: [0.49728693 0.48575806 0.48091492 0.48886799 0.51457923]\n",
      "error for param 7 is: [0.49474197 0.48428994 0.47928767 0.48676178 0.51205788]\n",
      "error for param 8 is: [0.49315497 0.48305003 0.47755446 0.48494203 0.50990736]\n",
      "error for param 9 is: [0.49214502 0.48204016 0.47721106 0.48424345 0.50909867]\n",
      "error for param 10 is: [0.49087897 0.48115483 0.47596032 0.4833043  0.5074252 ]\n",
      "error for param 11 is: [0.49038031 0.48041003 0.4747616  0.48147945 0.50665713]\n",
      "error for param 12 is: [0.49004719 0.48046445 0.47483247 0.48164277 0.5056621 ]\n",
      "error for param 13 is: [0.48967092 0.48020432 0.47497386 0.48058064 0.50482576]\n",
      "error for param 15 is: [0.48978513 0.47995163 0.4753768  0.48098616 0.50445624]\n"
     ]
    }
   ],
   "source": [
    "# use models from sklearn: RandomForest <-- change to other model from here\n",
    "params = [1,3,5,6,7,8,9,10,11,12,13,15]\n",
    "test_scores = []\n",
    "for param in params:\n",
    "    print('error for param ' + str(param) + ' is: ', end='')\n",
    "    clf = RandomForestRegressor(n_estimators=30, max_depth=param)\n",
    "    test_score = np.sqrt(-cross_val_score(clf, X_train, y_train, cv=5, scoring='neg_mean_squared_error'))\n",
    "    print(test_score)\n",
    "    test_scores.append(np.mean(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.350353570413594\n"
     ]
    }
   ],
   "source": [
    "# param_grid = {'n_estimators': [140, 160], 'max_depth': [16, 18, 20]}\n",
    "# grid_search = GridSearchCV(RandomForestRegressor(n_estimators=120, max_depth=10), param_grid, cv=5)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "# print(grid_search.best_params_)\n",
    "rf = RandomForestRegressor(n_estimators=140, max_depth=16)\n",
    "rf.fit(X_train, y_train)\n",
    "y_predicted = rf.predict(X_train)\n",
    "rms = sqrt(mean_squared_error(y_train, y_predicted))\n",
    "print(rms)\n",
    "y_pred = rf.predict(X_test)\n",
    "pd.DataFrame({\"id\": test_ids, \"relevance\": y_pred}).to_csv('midterm_data/RF_outputs.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearRegression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4985282255998273\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_predicted = lr.predict(X_train)\n",
    "rms = sqrt(mean_squared_error(y_train, y_predicted))\n",
    "print(rms)\n",
    "y_pred = lr.predict(X_test)\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] > 3:\n",
    "        y_pred[i] = 3\n",
    "pd.DataFrame({\"id\": test_ids, \"relevance\": y_pred}).to_csv('midterm_data/LR_outputs.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48724452390953804\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (166693,15) and (11,) not aligned: 15 (dim 1) != 11 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-2a18f2896edd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pythonenvs/py3/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \"\"\"\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pythonenvs/py3/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[0;32m--> 241\u001b[0;31m                                dense_output=True) + self.intercept_\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pythonenvs/py3/lib/python3.6/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (166693,15) and (11,) not aligned: 15 (dim 1) != 11 (dim 0)"
     ]
    }
   ],
   "source": [
    "svr = SVR(C=1.0, epsilon=0.2)\n",
    "svr.fit(X_train, y_train)\n",
    "y_predicted = svr.predict(X_train)\n",
    "rms = sqrt(mean_squared_error(y_train, y_predicted))\n",
    "print(rms)\n",
    "y_pred = lr.predict(X_test)\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] > 3:\n",
    "        y_pred[i] = 3\n",
    "pd.DataFrame({\"id\": test_ids, \"relevance\": y_pred}).to_csv('midterm_data/SVR_outputs.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/buqianzheng/pythonenvs/py3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5810266001031343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/buqianzheng/pythonenvs/py3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, y_train)\n",
    "y_predicted = xgb.predict(X_train)\n",
    "rms = sqrt(mean_squared_error(y_train, y_predicted))\n",
    "print(rms)\n",
    "y_pred = xgb.predict(X_test)\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] > 3:\n",
    "        y_pred[i] = 3\n",
    "pd.DataFrame({\"id\": test_ids, \"relevance\": y_pred}).to_csv('midterm_data/XGB_outputs.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated dictionary\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.concat((df_train, df_test), axis=0, ignore_index=True, sort=False)\n",
    "df_all['all_texts'] = df_all['product_title'] + ' . ' + df_all['product_description'] + ' . '\n",
    "all_text = df_all['all_texts'].values\n",
    "dictionary = Dictionary(list(tokenize(x, errors='ignore')) for x in all_text)\n",
    "print('generated dictionary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tfidf(text):\n",
    "    '''\n",
    "    calculate TF-IDF on bag of words vector\n",
    "    :param text: input text\n",
    "    :return:\n",
    "    '''\n",
    "    res = tfidf[dictionary.doc2bow(list(tokenize(text, errors='ignore')))]\n",
    "    return res\n",
    "\n",
    "\n",
    "def cos_sim(text1, text2):\n",
    "    '''\n",
    "    Calculate cosine similarity between two texts\n",
    "    :param text1: input string\n",
    "    :param text2: input string\n",
    "    :return: cosine similarity\n",
    "    '''\n",
    "    tfidf1 = to_tfidf(text1)\n",
    "    tfidf2 = to_tfidf(text2)\n",
    "    index = MatrixSimilarity([tfidf1],num_features=len(dictionary))\n",
    "    sim = index[tfidf2]\n",
    "    return float(sim[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCorpus(object):\n",
    "    '''\n",
    "    Convert dictionary to be bag of words representation.\n",
    "    '''\n",
    "    def __iter__(self):\n",
    "        for x in all_text:\n",
    "            yield dictionary.doc2bow(list(tokenize(x, errors='ignore')))\n",
    "\n",
    "# new an Corpus instance\n",
    "corpus = MyCorpus()\n",
    "# Calculate TF-IDF on the bag of words vectors\n",
    "tfidf = TfidfModel(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "calculating similarity between search terms and product title\n",
      "calculating similarity between search terms and product description\n",
      "calculating similarity between search terms and brand\n",
      "calculating similarity between search terms and material\n",
      "test:\n",
      "calculating similarity between search terms and product title\n",
      "calculating similarity between search terms and product description\n",
      "calculating similarity between search terms and brand\n",
      "calculating similarity between search terms and material\n"
     ]
    }
   ],
   "source": [
    "print('train:')\n",
    "print('calculating similarity between search terms and product title')\n",
    "df_train['tfidf_cos_sim_in_title'] = df_train.apply(lambda x: cos_sim(x['search_term'], x['product_title']), axis=1)\n",
    "print('calculating similarity between search terms and product description')\n",
    "df_train['tfidf_cos_sim_in_desc'] = df_train.apply(lambda x: cos_sim(x['search_term'], x['product_description']), axis=1)\n",
    "print('calculating similarity between search terms and brand')\n",
    "df_train['tfidf_cos_sim_in_brand'] = df_train.apply(lambda x: cos_sim(x['search_term'], x['brand']), axis=1)\n",
    "print('calculating similarity between search terms and material')\n",
    "df_train['tfidf_cos_sim_in_material'] = df_train.apply(lambda x: cos_sim(x['search_term'], x['material']), axis=1)\n",
    "df_train.to_csv('midterm_data/df_train_lev_tfidf_sim.csv', index=False)\n",
    "\n",
    "print('test:')\n",
    "print('calculating similarity between search terms and product title')\n",
    "df_test['tfidf_cos_sim_in_title'] = df_test.apply(lambda x: cos_sim(x['search_term'], x['product_title']), axis=1)\n",
    "print('calculating similarity between search terms and product description')\n",
    "df_test['tfidf_cos_sim_in_desc'] = df_test.apply(lambda x: cos_sim(x['search_term'], x['product_description']), axis=1)\n",
    "print('calculating similarity between search terms and brand')\n",
    "df_test['tfidf_cos_sim_in_brand'] = df_test.apply(lambda x: cos_sim(x['search_term'], x['brand']), axis=1)\n",
    "print('calculating similarity between search terms and material')\n",
    "df_test['tfidf_cos_sim_in_material'] = df_test.apply(lambda x: cos_sim(x['search_term'], x['material']), axis=1)\n",
    "df_test.to_csv('midterm_data/df_test_lev_tfidf_sim.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(text):\n",
    "    '''\n",
    "    Get the vector representation of input text.\n",
    "    :param text: input string\n",
    "    :return:\n",
    "    '''\n",
    "    res = np.zeros([128])\n",
    "    count = 0\n",
    "    for word in word_tokenize(text):\n",
    "        res += model[word]\n",
    "        count+=1\n",
    "    return res/count\n",
    "\n",
    "\n",
    "def w2v_cos_sim(text1, text2):\n",
    "    '''\n",
    "    Calculate cosine similarity between two word vectors.\n",
    "    :param text1: input string\n",
    "    :param text2: input string\n",
    "    :return: cosine similarity\n",
    "    '''\n",
    "    try:\n",
    "        w2v1 = get_vector(text1)\n",
    "        w2v2 = get_vector(text2)\n",
    "        sim = 1 - spatial.distance.cosine(w2v1, w2v2)\n",
    "        return float(sim)\n",
    "    except:\n",
    "        return float(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizing\n",
      "word 2 vec\n"
     ]
    }
   ],
   "source": [
    "# Load nltk tokenizer\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "# Convert all texts into a list of sentences, and then convert to be a list of words\n",
    "print('tokenizing')\n",
    "sentences = [tokenizer.tokenize(x) for x in all_text]\n",
    "sentences = [y for x in sentences for y in x]\n",
    "# Apply tokenizer\n",
    "w2v_corpus = [word_tokenize(x) for x in sentences]\n",
    "# Train model\n",
    "print('word 2 vec')\n",
    "model = Word2Vec(w2v_corpus, size=128, window=5, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "calculate cosine similarity between word vector and title\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/buqianzheng/pythonenvs/py3/lib/python3.6/site-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate cosine similarity between word vector and description\n",
      "calculate cosine similarity between word vector and brand\n",
      "calculate cosine similarity between word vector and material\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/buqianzheng/pythonenvs/py3/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in true_divide\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test:\n",
      "calculate cosine similarity between word vector and title\n",
      "calculate cosine similarity between word vector and description\n",
      "calculate cosine similarity between word vector and brand\n",
      "calculate cosine similarity between word vector and material\n"
     ]
    }
   ],
   "source": [
    "print('train:')\n",
    "print('calculate cosine similarity between word vector and title')\n",
    "df_train['w2v_cos_sim_in_title'] = df_train.apply(lambda x: w2v_cos_sim(x['search_term'], x['product_title']), axis=1)\n",
    "print('calculate cosine similarity between word vector and description')\n",
    "df_train['w2v_cos_sim_in_desc'] = df_train.apply(lambda x: w2v_cos_sim(x['search_term'], x['product_description']), axis=1)\n",
    "print('calculate cosine similarity between word vector and brand')\n",
    "df_train['w2v_cos_sim_in_brand'] = df_train.apply(lambda x: w2v_cos_sim(x['search_term'], x['brand']), axis=1)\n",
    "print('calculate cosine similarity between word vector and material')\n",
    "df_train['w2v_cos_sim_in_material'] = df_train.apply(lambda x: w2v_cos_sim(x['search_term'], x['material']), axis=1)\n",
    "df_train.to_csv('midterm_data/df_train_lev_tfidf_sim_w2v_sim.csv', index=False)\n",
    "\n",
    "print('test:')\n",
    "print('calculate cosine similarity between word vector and title')\n",
    "df_test['w2v_cos_sim_in_title'] = df_test.apply(lambda x: w2v_cos_sim(x['search_term'], x['product_title']), axis=1)\n",
    "print('calculate cosine similarity between word vector and description')\n",
    "df_test['w2v_cos_sim_in_desc'] = df_test.apply(lambda x: w2v_cos_sim(x['search_term'], x['product_description']), axis=1)\n",
    "print('calculate cosine similarity between word vector and brand')\n",
    "df_test['w2v_cos_sim_in_brand'] = df_test.apply(lambda x: w2v_cos_sim(x['search_term'], x['brand']), axis=1)\n",
    "print('calculate cosine similarity between word vector and material')\n",
    "df_test['w2v_cos_sim_in_material'] = df_test.apply(lambda x: w2v_cos_sim(x['search_term'], x['material']), axis=1)\n",
    "df_test.to_csv('midterm_data/df_test_lev_tfidf_sim_w2v_sim.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
